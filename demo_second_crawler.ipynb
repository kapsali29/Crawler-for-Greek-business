{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_email(soup1):\n",
    "    import re\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    valid = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
    "    ret_email = []\n",
    "    get_email = soup1.find_all(text=re.compile(r'[\\w\\.-]+@[\\w\\.-]+'))\n",
    "    if get_email !=[]:\n",
    "        for e in get_email:\n",
    "            if e !=[]:\n",
    "                match = re.search(r'[\\w\\.-]+@[\\w\\.-]+', e)\n",
    "                if match !=None:\n",
    "                    ret_email.append(match.group(0))\n",
    "        ret = list(set(ret_email))\n",
    "    else:\n",
    "        tmp1 = soup1.find_all('a',href=re.compile(r'mailto:'),attrs={'href' : True})\n",
    "        tmp11 = [t['href'] for t in tmp1]\n",
    "        tmp2 = soup1.find_all(text=re.compile(r'^([eE]mail|e|Email:|e-mail|E-mail:|\tE-MAIL)'))\n",
    "        get_email = tmp11+tmp2\n",
    "        if get_email!=[]:\n",
    "            for e in get_email:\n",
    "                if e !=[]:\n",
    "                    match = re.search(r'[\\w\\.-]+@[\\w\\.-]+', e)\n",
    "                    if match!=None:\n",
    "                        ret_email.append(match.group(0))\n",
    "            ret = list(set(ret_email))\n",
    "        else:\n",
    "            ret = []\n",
    "    return ret\n",
    "def email_crawler(url):\n",
    "    from bs4 import BeautifulSoup\n",
    "    from urllib.parse import urljoin\n",
    "    import requests\n",
    "    import re\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content,'lxml')\n",
    "    valid_url = re.compile(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)')\n",
    "    goto_contact = soup.find('a',text=re.compile(r'^([Εε]πικοινωνία(?!.*επενδυτές).*$|[Cc]ontact [Us]?|Στοιχεία επικοινωνίας|Επικοινωνία|CONTACTS|Επικοινωνία|Επικοινωνείστε μαζί μας|INFO|ΕΠΙΚΟΙΝΩΝΙΑ|ΕΠΙΚΟΙΝΩΝΗΣΤΕ ΜΑΖΙ ΜΑΣ|ΕΠΙΚΟΙΝΩΝΙΑ|Επικοινωνια|[Cc]ontact|Contacts|CONTACT|[εΕ]πικοινωνια|ÎÏÎ¹ÎºÎ¿Î¹Î½ÏÎ½Î¯Î±|Επικοινωνία(?!.*επενδυτές).*$|Επικοινώνησε μαζί μας|^(ÎÏÎ¹ÎºÎ¿Î¹Î½ÏÎ½Î¹Î±)|ÎµÏÎ¹ÎºÎ¿Î¹Î½ÏÎ½Î¯Î±|ÅÐÉÊÏÉÍÙÍÉÁ|Πού θα μας βρείτε|[Cc]ontact|ÎÎ ÎÎÎÎÎÎ©ÎÎÎ|ΕΠΙΚ/ΝΙΑ|Επικοινωνήστε μαζί μας|Που είμαστε|ΕΠΙΚΟΙΝΩΝΙΑ|Επικοινωνια|Στοιχεία επικοινωνίας|Φόρμα Επικοινωνίας|Επικοινωνήστε μαζί μας|Επικοινωνήστε μαζί μας)'),attrs={'href' : re.compile(r'^(?!.*(javascript|mailto|Mailto))')})\n",
    "    if goto_contact == None:\n",
    "        goto_contact = soup.find(href = re.compile(r'[cC]ontact[-us]?\\b|info|CONTACT|Forma Epikoinwnias|communication|EPIKOINONIA|katastimata|know|contact_us|epik|ΕΠΙΚΟΙΝΩΝΙΑ|stoixeia-epikoinonias|Contacts|communication|epikoinia|Contact|contact|[eE]pikoin[ow]nia\\b|info|contact|%C5%F0%E9%EA%EF%E9%ED%F9%ED%DF%E1|contac-us|epikoinwnia|where-we-are|find-us|2cont|contact|επικοινωνία|epikinonia|επικοινωνια|%ce%b5%cf%80%ce%b9%ce%ba%ce%bf%ce%b9%ce%bd%cf%89%ce%bd%ce%af%ce%b1|EPIKINONIA|contact-us|epikoinwnia|epikoinonia|Eπικοινωνία|Επικοινωνία|καταστήματα|επικοινωνια|epsilonpiiotakappaomicroniotanuomeganuiotaalpha|GrFeed|madres-oikodomikwn-ylikwn-volou.html|epikoinoneste-mazi-mas|/1/gr/8_3/8.htm'))\n",
    "    if goto_contact !=None and 'mailto' not in goto_contact['href'] and 'Mailto' not in goto_contact['href']:\n",
    "        if valid_url.search(goto_contact['href']):\n",
    "            contact_link = goto_contact['href']\n",
    "        else:\n",
    "            contact_link = urljoin(url,goto_contact['href'])\n",
    "        r1 = requests.get(contact_link)\n",
    "    else:\n",
    "        r1 = r\n",
    "        contact_link = url\n",
    "    soup1 = BeautifulSoup(r1.content,'lxml')\n",
    "    emails = find_email(soup1)\n",
    "    if emails == []:\n",
    "        emails = rec_find_email(contact_link)\n",
    "    emtotal = []\n",
    "    for em in emails:\n",
    "        if '.gif' not in em:\n",
    "            emtotal.append(em)\n",
    "    return emtotal\n",
    "def rec_find_email(link):\n",
    "    import time\n",
    "    import selenium\n",
    "    import re\n",
    "    from selenium import webdriver\n",
    "    import os\n",
    "    import time\n",
    "    from selenium.common.exceptions import UnexpectedAlertPresentException\n",
    "    from selenium.common.exceptions import NoAlertPresentException\n",
    "    valid = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
    "    emails = []\n",
    "    path=\"C:\\\\Users\\\\User\\\\Desktop\\\\diploma thesis Data Science\\\\chromedriver.exe\"\n",
    "    driver=webdriver.Chrome(path)\n",
    "    driver.get(link)\n",
    "    time.sleep(1)\n",
    "    global alert\n",
    "    while alert_accept(driver) == True:\n",
    "        alert_accept(driver)\n",
    "    \n",
    "    cards = driver.find_elements_by_xpath(\"//a[contains(@href,'mailto:')]\")\n",
    "    if cards !=[]:\n",
    "        for c in cards:\n",
    "            if c.text != '':\n",
    "                emails.append(c.text)\n",
    "            else:\n",
    "                emails.append(c.get_attribute('href'))\n",
    "        driver.close()\n",
    "        return list(set(emails))\n",
    "    else:\n",
    "        cards1 = driver.find_elements_by_xpath(\"//*[contains(text(), '@')]\")\n",
    "        rettt = []\n",
    "        if cards1 !=[]:\n",
    "            res = [c.text for c in cards]\n",
    "            if res !=[]:\n",
    "                valid = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
    "                match = re.search(r'[\\w\\.-]+@[\\w\\.-]+', e)\n",
    "                if match !=None:\n",
    "                    rettt.append(match.group(0))\n",
    "            driver.close()\n",
    "            return rettt\n",
    "        else:\n",
    "            driver.close()\n",
    "            return []\n",
    "    \n",
    "def alert_accept(driver):\n",
    "    from selenium.common.exceptions import UnexpectedAlertPresentException\n",
    "    from selenium.common.exceptions import NoAlertPresentException\n",
    "    try:\n",
    "        alert = driver.switch_to_alert()\n",
    "        alert.accept()\n",
    "        return True\n",
    "    except UnexpectedAlertPresentException:\n",
    "        return False\n",
    "    except NoAlertPresentException:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def certif_first(url,r8):\n",
    "    import re \n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    from pprint import pprint\n",
    "    soup8 = BeautifulSoup(r8.content,'lxml')\n",
    "    results = soup8.find_all('a',text=re.compile(r'|Quality Assurance|ΠΟΙΟΤΙΚΑ ΧΑΡΑΚΤΗΡΙΣΤΙΚΑ|ΠΙΣΤΟΠΟΙΗΤΙΚΑ|ΔΙΑΠΙΣΤΕΥΣΗ|[Δδ]ιαπίστευση|[Vv]erifications|VERIFICATIONS|quality-insurance|Πιστοποιήσεις|Ποιότητα|Ποιότητα|Certificates|ISO|CERTIFICATIONS|Quality|QUALITY|[Cc]ertifications|CERTIFICATES|QUALITY|Quality|Ποιοτητα|Πιστοποιησεις|Διασφάλιση ποιότητας|ΠΟΙΟΤΗΤΑ|ΠΙΣΤΟΠΟΙΗΣΗ|Η Εταιρεία|Πιστοποιητικά|ΕΤΑΙΡΕΙΑ|Σχετικά με εμάς|Παραγωγή προϊόντων|Προφίλ|Η εταιρεία μας|Για Εμάς|Πολιτική ποιότητας|Η εταιρεία|ΠΡΟΦΙΛ|ΠΙΣΤΟΠΟΙΗΣΕΙΣ|ΠΟΙΟΤΗΤΑ|Η ΕΤΑΙΡΙΑ ΜΑΣ|[Ππ]ροφίλ|Προφίλ|Παραγωγή|[cC]ompany|Σχετικά με μας|COMPANY|ΕΤΑΙΡΙΑ|Εταιρική ταυτότητα|[Ιι]στορικό|ΙΣΤΟΡΙΚΟ|HISTORY|[Hh]istory|ABOUT|ΠΟΙΟΙ ΕΙΜΑΣΤΕ|[A]bout|ΣΧΕΤΙΚΑ|[Σσ]χετικά|ΠΟΙΟΙ ΕΙΜΑΣΤΕ|Η ΕΤΑΙΡΕΙΑ'),attrs={'href' : re.compile(r'^(?!.*(javascript|mailto|Mailto))')})\n",
    "    res1 = soup8.find_all('a',href = re.compile(r'quality|diasfalisi-poiotitas|comp|[πΠ]οιότητα|poiotika-xarakthristika|[πΠ]οιοτητα|poioteta|quality-insurance|QUALITY|[Pp]istop|certificate|cetifications|Quality|verifications|diapisteush|about|profil|profile|PROFILE|company|etareia|etairia|poiotita|pistopoiiseis|pistopoiish'))\n",
    "    t = list(set(results+res1))\n",
    "    return t\n",
    "\n",
    "def certif_sec(url3,url): \n",
    "    import re \n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    from pprint import pprint\n",
    "    r = requests.get(url3)\n",
    "    soup = BeautifulSoup(r.content,'lxml')\n",
    "    text = soup.find_all(text=re.compile(r'(ISO \\d*:\\d{4})|HACCP|BRC|KIR|(ISO \\d*)|ISO:\\d*|(ΙSO \\d*:\\d{4})|OHSAS|EUROCERT|AGROCERT|ΕΛΟΤ|AGRO|CE|HACCP|TUV|ΕΛΟΤ|(ISO \\d*:\\d{4})'))\n",
    "    total = []\n",
    "    for txt in text:\n",
    "        iso = re.findall('(ISO \\d*:\\d{4}|(ISO \\d*)|(ΙSO \\d*:\\d{4})|(ΙSO \\d*:[\\s]?\\d{4})|ISO:\\d*|(ΕΛΟΤ \\d*:[\\s]?\\d{4})|(AGRO \\d*-\\d*))', txt)\n",
    "        if iso !=[]:\n",
    "            for item in iso:\n",
    "                for s in item:\n",
    "                    if s!='':\n",
    "                        total.append(s)\n",
    "        haccp = re.findall('(HACCP)|(BRC)|(KIR)|(OHSAS \\d*)|(EUROCERT)|(AGROCERT)', txt)\n",
    "        if haccp !=[]:\n",
    "            for item in haccp:\n",
    "                for s in item:\n",
    "                    if s!='':\n",
    "                        total.append(s)\n",
    "    return list(set(total))\n",
    "\n",
    "def find_certif(url,r8):\n",
    "    import re\n",
    "    from urllib.parse import urlparse\n",
    "    from urllib.parse import urljoin\n",
    "    from requests.exceptions import InvalidSchema\n",
    "    res = certif_first(url,r8)\n",
    "    parsed = list(urlparse(url))\n",
    "    schema = parsed[0]+'://'+parsed[1]+'/'\n",
    "    valid_url = re.compile(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)')\n",
    "    tmp = []\n",
    "    for url3 in res:\n",
    "        if url3.has_attr('href'):\n",
    "            try:\n",
    "                if 'mailto' not in url3['href'] or 'Mailto' not in url3['href']:\n",
    "                    if valid_url.search(url3['href']):\n",
    "                        thisurl = url3['href']\n",
    "                    else:\n",
    "                        thisurl = urljoin(url,url3['href'])\n",
    "                    resp = certif_sec(thisurl,url)\n",
    "                    if resp !=[]:\n",
    "                        tmp+=resp\n",
    "                else:\n",
    "                    continue\n",
    "            except InvalidSchema:\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "    tmp+= certif_sec(url,url)\n",
    "    return list(set(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_phone(url):\n",
    "    import re\n",
    "    from bs4 import BeautifulSoup\n",
    "    import requests\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text,'lxml')\n",
    "    alltext = soup.findAll(text=True)\n",
    "    visible_texts = filter(visible, alltext)\n",
    "    alltext = list(visible_texts)\n",
    "    #print(alltext)\n",
    "    phones = []\n",
    "    for txt in alltext:\n",
    "        txt = txt.replace('(',txt)\n",
    "        #xt = txt.replace(')',txt)\n",
    "        txt = re.sub('\\+30','',txt)\n",
    "        if re.findall(r'[26]\\d{9}',txt) !=[]:\n",
    "            phones+=re.findall(r'[26]\\d{9}',txt)\n",
    "        if re.findall(r'[26]\\d{4}[\\s\\.\\-\\–]{1,3}\\d{5}',txt) !=[]:\n",
    "            phones+=re.findall(r'[26]\\d{4}[\\s\\.\\-]{1,3}\\d{5}',txt)\n",
    "        if re.findall('[26]\\d{3}[\\s\\.\\-\\–]{1,3}\\d{6}',txt) !=[]:\n",
    "            phones+=re.findall('[26]\\d{3}[\\s\\.\\-]{1,3}\\d{6}',txt)\n",
    "        if re.findall(r'[26]\\d{2}[\\s\\.\\-\\–]{1,3}\\d{7}',txt) !=[]:\n",
    "            phones+=re.findall(r'[26]\\d{2}[\\s\\.\\-]{1,3}\\d{7}',txt)\n",
    "        if re.findall(r'[26]\\d{2}[\\s\\.\\–\\-]{1,3}\\d{4}[\\s\\.\\-\\–]{1,3}\\d{3}',txt) !=[]:\n",
    "            phones+=re.findall(r'[26]\\d{2}[\\s\\.\\–\\-]{1,3}\\d{4}[\\s\\.\\-\\–]{1,3}\\d{3}',txt)\n",
    "        if re.findall(r'[26]\\d{2}[\\s\\.\\–\\-]{1,3}\\d{3}[\\s\\.\\-\\–]{1,3}\\d{4}',txt) !=[]:\n",
    "            phones+=re.findall(r'[26]\\d{2}[\\s\\.\\–\\-]{1,3}\\d{3}[\\s\\.\\-\\–]{1,3}\\d{4}',txt)\n",
    "        if re.findall(r'[26]\\d{2}[\\s\\.\\–\\-]{1,3}\\d{2}[\\s\\.\\-\\–]{1,3}\\d{5}',txt) !=[]:\n",
    "            phones+=re.findall(r'[26]\\d{2}[\\s\\.\\–\\-]{1,3}\\d{2}[\\s\\.\\-\\–]{1,3}\\d{5}',txt)\n",
    "        if re.findall(r'[26]\\d{2}[\\s\\.\\–\\-]{1,3}\\d{2}[\\s\\.\\-\\–]{1,3}\\d{2}[\\s\\.\\-\\–]\\d{3}',txt) !=[]:\n",
    "            phones+=re.findall(r'[26]\\d{2}[\\s\\.\\–\\-]{1,3}\\d{2}[\\s\\.\\-\\–]{1,3}\\d{2}[\\s\\.\\-\\–]\\d{3}',txt)\n",
    "        if re.findall(r'[26]\\d{4}[\\s\\.\\–\\-]{1,3}\\d{2}[\\s\\.\\-\\–]{1,3}\\d{3}',txt) !=[]:\n",
    "            phones+=re.findall(r'[26]\\d{4}[\\s\\.\\–\\-]{1,3}\\d{2}[\\s\\.\\-\\–]{1,3}\\d{3}',txt)\n",
    "        if re.findall(r'[26]\\d{3}[\\s\\.\\–\\-]{1,3}\\d{3}[\\s\\.\\-\\–]{1,3}\\d{3}',txt) !=[]:\n",
    "            phones+=re.findall(r'[26]\\d{3}[\\s\\.\\–\\-]{1,3}\\d{3}[\\s\\.\\-\\–]{1,3}\\d{3}',txt)\n",
    "        if re.findall(r'[23]\\d{3}[\\s\\.\\–\\-]{1,3}\\d{2}[\\s\\.\\-\\–]{1,3}\\d{4}',txt) !=[]:\n",
    "            phones+=re.findall(r'[23]\\d{3}[\\s\\.\\–\\-]{1,3}\\d{2}[\\s\\.\\-\\–]{1,3}\\d{4}',txt)\n",
    "        if re.findall(r'[23]\\d{3}[\\s\\.\\–\\-]{1,3}\\d{2}[\\s\\.\\-\\–]{1,3}\\d{2}[\\s\\.\\-\\–]\\d{2}',txt) !=[]:\n",
    "            phones+=re.findall(r'[23]\\d{3}[\\s\\.\\–\\-]{1,3}\\d{2}[\\s\\.\\-\\–]{1,3}\\d{2}[\\s\\.\\-\\–]\\d{2}',txt)\n",
    "    return list(set(phones))\n",
    "def finder(url,r):\n",
    "    from bs4 import BeautifulSoup\n",
    "    from urllib.parse import urljoin\n",
    "    import requests\n",
    "    import re\n",
    "    soup = BeautifulSoup(r.content,'lxml')\n",
    "    valid_url = re.compile(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)')\n",
    "    goto_contact = soup.find('a',text=re.compile(r'^([Εε]πικοινωνία(?!.*επενδυτές).*$|[Cc]ontact [Us]?|Στοιχεία επικοινωνίας|Επικοινωνία|CONTACTS|Επικοινωνία|Επικοινωνείστε μαζί μας|INFO|ΕΠΙΚΟΙΝΩΝΙΑ|ΕΠΙΚΟΙΝΩΝΗΣΤΕ ΜΑΖΙ ΜΑΣ|ΕΠΙΚΟΙΝΩΝΙΑ|Επικοινωνια|[Cc]ontact|Contacts|CONTACT|[εΕ]πικοινωνια|ÎÏÎ¹ÎºÎ¿Î¹Î½ÏÎ½Î¯Î±|Επικοινωνία(?!.*επενδυτές).*$|Επικοινώνησε μαζί μας|^(ÎÏÎ¹ÎºÎ¿Î¹Î½ÏÎ½Î¹Î±)|ÎµÏÎ¹ÎºÎ¿Î¹Î½ÏÎ½Î¯Î±|ÅÐÉÊÏÉÍÙÍÉÁ|Πού θα μας βρείτε|[Cc]ontact|ÎÎ ÎÎÎÎÎÎ©ÎÎÎ|ΕΠΙΚ/ΝΙΑ|Επικοινωνήστε μαζί μας|Που είμαστε|ΕΠΙΚΟΙΝΩΝΙΑ|Επικοινωνια|Στοιχεία επικοινωνίας|Φόρμα Επικοινωνίας|Επικοινωνήστε μαζί μας|Επικοινωνήστε μαζί μας)'),attrs={'href' : re.compile(r'^(?!.*(javascript|mailto|Mailto))')})\n",
    "    if goto_contact == None:\n",
    "        goto_contact = soup.find(href = re.compile(r'contact|[cC]ontact[-us]?\\b|info|CONTACT|Forma Epikoinwnias|communication|EPIKOINONIA|katastimata|know|contact_us|epik|ΕΠΙΚΟΙΝΩΝΙΑ|stoixeia-epikoinonias|Contacts|communication|epikoinia|Contact|contact|[eE]pikoin[ow]nia\\b|info|contact|%C5%F0%E9%EA%EF%E9%ED%F9%ED%DF%E1|contac-us|epikoinwnia|where-we-are|find-us|2cont|contact|επικοινωνία|epikinonia|επικοινωνια|%ce%b5%cf%80%ce%b9%ce%ba%ce%bf%ce%b9%ce%bd%cf%89%ce%bd%ce%af%ce%b1|EPIKINONIA|contact-us|epikoinwnia|epikoinonia|Eπικοινωνία|Επικοινωνία|καταστήματα|επικοινωνια|epsilonpiiotakappaomicroniotanuomeganuiotaalpha|GrFeed|madres-oikodomikwn-ylikwn-volou.html|epikoinoneste-mazi-mas|epikoinoniste|/1/gr/8_3/8.htm|%ce%b5%cf%80%ce%b9%ce%ba%ce%bf%ce%b9%ce%bd%cf%89%ce%bd%'))\n",
    "    if goto_contact !=None and 'mailto' not in goto_contact['href'] and 'Mailto' not in goto_contact['href'] and 'mailTo' not in goto_contact['href'] :\n",
    "        if valid_url.search(goto_contact['href']):\n",
    "            contact_link = goto_contact['href']\n",
    "        else:\n",
    "            contact_link = urljoin(url,goto_contact['href'])\n",
    "    else:\n",
    "        contact_link = url\n",
    "    phone_numbers = find_phone(contact_link)\n",
    "    return ','.join(phone_numbers)\n",
    "def visible(element):\n",
    "    import re\n",
    "    if element.parent.name in ['style', 'script', '[document]', 'head', 'title']:\n",
    "        return False\n",
    "    elif re.match('<!--.*-->', str(element)):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def second_find(link):\n",
    "    import re\n",
    "    from bs4 import BeautifulSoup\n",
    "    import requests\n",
    "    r = requests.get(link)\n",
    "    soup = BeautifulSoup(r.content,'lxml')\n",
    "    texts = soup.find_all(text=True)\n",
    "    visible_texts = filter(visible, texts)\n",
    "    res = list(visible_texts)\n",
    "    totaltext = ' '.join(res)\n",
    "    totaltext = totaltext.replace('\\n',' ')\n",
    "    totaltext = totaltext.replace('\\r',' ')\n",
    "    totaltext = totaltext.replace('»','')\n",
    "    totaltext = totaltext.replace('«','')\n",
    "    totaltext = re.sub(r'\\'','',totaltext)\n",
    "    totaltext = re.sub(r'\"','',totaltext)\n",
    "    totaltext = re.sub(r'“','',totaltext)\n",
    "    totaltext = re.sub(r'”','',totaltext)\n",
    "    #print(totaltext)\n",
    "    matches = re.compile(r'(([Α-ΩΆ-Ώ][\\w-]+[.]?|[A-ZΆ-Ώ][\\w-]+[.]?)(\\s(\\&\\s)?([Α-ΩΆ-Ώ][.\\w-]*|[A-ZΆ-Ώ][.\\w-]*))*)\\s(\\bΙ[.]?Κ[.]?Ε\\b|\\bΕ[.]?Π[.]?Ε\\b|\\bA[.]?E\\b|\\bE[.]?Π[.]?E\\b|\\bA[.]?E\\b|\\bΕ[.]?Ε\\b|\\bLTD\\b|\\b[Ll]td\\b|\\bΑ[.]?Ε\\b|\\bΟ[.]?Ε[.]?\\b|\\b[Hh][oO][tT][eE][lL]\\b|\\b[R]esort[s]?\\b|ΑΝΩΝΥΜΗ ΕΤΑΙΡΕΙΑ|\\bS[.]?A\\b|\\bC[oO][.]\\b|\\bIKE\\b|\\bApartments\\b|\\bΑ[.]?Β[.]?Ε[.]?Ε\\b|\\bS.M.P.C\\b|\\bΑ[.]?Τ[.]?Ε\\b|\\bΑ[.]?Ε[.]?Β[.]?Ε\\b|\\bΑ[.]?Ε[.]?Ε\\b|\\bO[.]?E\\b|\\bΑΓ[.]?ΟΕ\\b|\\bΜ[.]?Ε[.]?Π[.]?Ε\\b|\\bE[.]?Π[.]?Ε\\b)').search(totaltext)\n",
    "    if matches !=None:\n",
    "        return matches.group(0)\n",
    "    else:\n",
    "        matches1 = re.compile(r'([οΟ]ργανισμός|[ε]ταιρεία[ς]?|εταιρεία|εταιρεία|company|[ε]ταιρία[ς]?|Όμιλος|όμιλος|εταιρεία[ς]? μας|εταιρία|βιοτεχνία|εταιρία[ς]? μας|επωνυμία|[Εε]πιχείριση|όμιλος εταιρειών|[Οο]ίκος|Ξενοδοχείο|ΟΙΚΟΣ|κατάστημα|καταστήματα|επιχείρησης|δωμάτια|επιχείρηση|καταστημάτων)\\s{1,2}(([Α-Ω][\\w-]+[.]?|[A-Z][\\w-]+[.]?)(\\s(\\&\\s)?([Α-Ω][.\\w-]*|[A-Z][.\\w-]*))*)').search(totaltext)\n",
    "        if matches1 !=None:\n",
    "            return matches1.group(0)\n",
    "        else:\n",
    "            return ''\n",
    "def business_name(url,r):\n",
    "    import re\n",
    "    import requests\n",
    "    from urllib.parse import urljoin\n",
    "    from bs4 import BeautifulSoup\n",
    "    #r = requests.get(url)\n",
    "    soupc = BeautifulSoup(r.content,'lxml')\n",
    "    theurls = soupc.find_all('a',text=re.compile(r'[Ππ]ροφίλ|Εταιρική ταυτότητα|Ποιοι Είμαστε|Η εταιρεία μας|PROFIILE|profile|HISTORY|[hH]istory|[Εε]ταιρια|[Εε]ταιρία|ΣΧΕΤΙΚΑ|ΙΣΤΟΡΙΚΟ|Ποιοί Είμαστε|[Εε]ταιρεία|ΕΤΑΙΡΕΙΑ|ΕΤΑΙΡΙΑ|Όμιλος|η εταιρεία μας|ΠΡΟΦΙΛ|λίγα λόγια για εμάς|Η ΕΤΑΙΡΙΑ ΜΑΣ|ΥΠΗΡΕΣΙΕΣ|Εισαγωγές - Εξαγωγές|Εξαγωγές|Δίκτυο Διανομής|Εξαγωγική δραστηριότητα|Το δίκτυο μας|Εξωτερικό|Δίκτυο εξωτερικού|Δίκτυο|Εταιρεία|Δραστηριότητες|[Cc]ompany|COMPANY|[Aa]bout|ABOUT|ΣΧΕΤΙΚΑ|[Σσ]χετικά|EXPORTS|[Ee]xports|[Pp]rofile|PROFILE|Εταιρική Ταυτότητα'))\n",
    "    theurls1 = soupc.find_all('a',href=re.compile(r'company|etairia|etaireia|εταιρεια|about|h-agrimon.html|arousiasi-etaireias|profile|Εταιρία|profil|about|about_us|προφίλ|εταιρεία|etairia|εταιρία|poioi-eimaste|[Cc]ontact|epikoinwnia|CONTACT|communication|EPIKOINONIA|contact_us|epik|ΕΠΙΚΟΙΝΩΝΙΑ|stoixeia-epikoinonias|Contacts|communication|epikoinia|Contact|contact|[eE]pikoin[ow]nia\\b|contact|%C5%F0%E9%EA%EF%E9%ED%F9%ED%DF%E1|contac-us|epikoinwnia|where-we-are|find-us|contact|επικοινωνία|epikinonia|επικοινωνια|%ce%b5%cf%80%ce%b9%ce%ba%ce%bf%ce%b9%ce%bd%cf%89%ce%bd%ce%af%ce%b1|EPIKINONIA|contact-us|epikoinwnia|epikoinonia|Eπικοινωνία|Επικοινωνία|καταστήματα|επικοινωνια|epsilonpiiotakappaomicroniotanuomeganuiotaalpha|GrFeed|madres-oikodomikwn-ylikwn-volou.html|epikoinoneste-mazi-mas|/1/gr/8_3/8.htm|%cf%80%cf%81%ce%bf%cf%88%ce%b7%ce%bc%ce%b5%ce%bd%ce%b1-%ce%ba%ce%b1%cf%84%ce%b5%cf%88%cf%85%ce%b3%ce%bc%ce%b5%ce%bd%ce%b1-%ce%b1%cf%81%cf%84%ce%bf%cf%83%ce%ba%ce%b5%cf%85%ce%b1%cf%83%ce%bc%ce%b1%cf%84/|page_id=881'))\n",
    "    theurls +=theurls1\n",
    "    #print(theurls)\n",
    "    valid_url = re.compile(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)')\n",
    "    res = []\n",
    "    if theurls !=[]:\n",
    "        for t in theurls:\n",
    "            if t.has_attr('href'):\n",
    "                if t['href'] == '#':\n",
    "                    continue\n",
    "                if valid_url.search(t['href']):\n",
    "                    thislink = t['href']\n",
    "                else:\n",
    "                    thislink = urljoin(url,t['href'])\n",
    "                t = second_find(thislink)\n",
    "                if t !='':\n",
    "                    res.append(t)\n",
    "            else:\n",
    "                continue\n",
    "            if len(res) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        if res == []:\n",
    "            t1 = second_find(url)\n",
    "            if t1 !='':\n",
    "                results.append(t1)\n",
    "        results = list(set(res))\n",
    "        if results == []:\n",
    "            tmp = soupc.title\n",
    "            if tmp !=None:\n",
    "                results = tmp.string.strip()\n",
    "                results = re.sub(r'ΚΕΝΤΡΙΚΗ|[Κκ]εντρική|[Σσ]ελίδα|[Mm]ain|MAIN|[Ww]elcome to|Well come to|[Pp]rofile|[iI]ntro|INTRO|[Ii]ntroduction|INTRODUCTION|ΠΡΟΦΙΛ|[πΠ]ροφίλ|ΑΝΑΖΗΤΗΣΗ|[Αα]ναζήτηση|[πΠ]ληροφορίες|HOME|[Hh]ome','',results)\n",
    "                results = re.sub(r'ΣΕΛΙΔΑ|[Σσ]ελίδα|PAGE|[Pp]age|Αρχική|WELCOME TO|ΚΑΛΩΣ ΗΡΘΕΣ|ΑΡΧΙΚΗ','',results)\n",
    "                return results\n",
    "            else:\n",
    "                return ''\n",
    "        else:\n",
    "            return results[0]\n",
    "def visible(element):\n",
    "    import re\n",
    "    if element.parent.name in ['style', 'script', '[document]', 'head', 'title']:\n",
    "        return False\n",
    "    elif re.match('<!--.*-->', str(element)):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_countries(url):\n",
    "    import pandas as pd\n",
    "    import re\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    from pprint import pprint\n",
    "    from nltk.tokenize import RegexpTokenizer\n",
    "    from collections import Counter\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content,'lxml')\n",
    "    texts = soup.findAll(text=True)\n",
    "    data = pd.read_csv('country_names.txt', header = None)\n",
    "    visible_texts = filter(visible, texts)\n",
    "    res = list(visible_texts)\n",
    "    totaltext = ' '.join(res)\n",
    "    #print(totaltext)\n",
    "    countries = list(data[1])\n",
    "    countries = [c.strip(' ') for c in countries]\n",
    "    lc = [c.lower() for c in countries]\n",
    "    lu = [c.upper() for c in countries]\n",
    "    data = pd.read_csv('greek-countries.txt', header = None,encoding = 'utf8')\n",
    "    gc = list(data[0])\n",
    "    gc = [c.strip(' ').replace('\\ufeff','') for c in gc]\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens2 = tokenizer.tokenize(totaltext)\n",
    "    ret_count = []\n",
    "    for tok in tokens2:\n",
    "        if tok in countries:\n",
    "            ret_count.append(tok)\n",
    "        if tok in lc:\n",
    "            ret_count.append(tok)\n",
    "        if tok in lu:\n",
    "            ret_count.append(tok)\n",
    "        if tok in gc:\n",
    "            ret_count.append(tok)\n",
    "    total = []\n",
    "    for tok in ret_count:\n",
    "        if tok == 'Greece' or tok=='Greek' or tok=='greek' or tok=='GREECE' or tok=='GREEK' or tok=='ΕΛΛΑΔΑ' or tok=='ελλάδα' or tok=='Ελλάδα' or tok=='ελληνική' or tok=='Ελληνική' or tok=='ΕΛΛΗΝΙΚΗ':\n",
    "            total.append('Ελλάδα')\n",
    "        else:\n",
    "            total.append(tok)\n",
    "    clist = Counter(total)\n",
    "    return list(clist.keys())\n",
    "def country_data(url):\n",
    "    import re\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    from pprint import pprint\n",
    "    from collections import Counter\n",
    "    rc = requests.get(url)\n",
    "    soupc = BeautifulSoup(rc.content,'lxml')\n",
    "    theurls = soupc.find_all('a',text=re.compile(r'[Ππ]ροφίλ|Εταιρική ταυτότητα|Ποιοι Είμαστε|Η εταιρεία μας|PROFIILE|profile|HISTORY|[hH]istory|[Εε]ταιρια|[Εε]ταιρία|ΣΧΕΤΙΚΑ|ΙΣΤΟΡΙΚΟ|Ποιοί Είμαστε|[Εε]ταιρεία|ΕΤΑΙΡΕΙΑ|ΕΤΑΙΡΙΑ|Όμιλος|η εταιρεία μας|ΠΡΟΦΙΛ|λίγα λόγια για εμάς|Η ΕΤΑΙΡΙΑ ΜΑΣ|ΥΠΗΡΕΣΙΕΣ|Εισαγωγές - Εξαγωγές|Εξαγωγές|Δίκτυο Διανομής|Εξαγωγική δραστηριότητα|Το δίκτυο μας|Εξωτερικό|Δίκτυο εξωτερικού|Δίκτυο|Εταιρεία|Δραστηριότητες|[Cc]ompany|COMPANY|[Aa]bout|ABOUT|ΣΧΕΤΙΚΑ|[Σσ]χετικά|EXPORTS|[Ee]xports|[Pp]rofile|PROFILE|Εταιρική Ταυτότητα'))\n",
    "    theurls1 = soupc.find_all('a',href=re.compile(r'company|etairia|etaireia|about|profile|profil|προφίλ|εταιρεία|εταιρία|h-agrimon.html'))\n",
    "    theurls +=theurls1\n",
    "    valid_url = re.compile(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)')\n",
    "    total = []\n",
    "    if theurls !=[]:\n",
    "        for purl in theurls:\n",
    "            if purl.has_attr('href'):\n",
    "                if valid_url.search(purl['href']):\n",
    "                    thislink = purl['href']\n",
    "                else:\n",
    "                    thislink = url+purl['href'].lstrip('/')\n",
    "                total.append(find_countries(thislink))\n",
    "                if total !=[]:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "    total.append(find_countries(url))\n",
    "    cc = Counter(x for xs in total for x in set(xs))\n",
    "    ret_cc = list(cc.keys())\n",
    "    if ret_cc == ['Ελλάδα'] or ret_cc == ['ΕΛΛΑΔΑ'] or ret_cc == ['GREECE'] or ret_cc == ['Greece'] or ret_cc == ['greece'] or ret_cc == ['ελληνική', 'Ελλάδα'] or ret_cc == ['ελληνική', 'Ελληνική', 'Ελλάδα'] or ret_cc ==['ΕΛΛΗΝΙΚΗ', 'Ελλάδα'] or ret_cc == ['ΕΛΛΑΔΑ', 'Ελληνική', 'Ελλάδα'] or ret_cc == ['ελληνική'] or ret_cc ==['Ελληνική', 'Ελλάδα'] or ret_cc ==['Ελληνική', 'ελληνική'] or ret_cc == ['Ελλάδα', 'ελληνική'] or ret_cc ==['Ελληνική', 'ΕΛΛΗΝΙΚΗ'] or ret_cc ==['Ελληνική'] or ret_cc ==['Greece', 'Ελληνική'] or ret_cc==['Ελληνική','Greece'] or ret_cc==['Greece', 'Greek', 'Ελληνική'] or ret_cc==['Ελληνική','Greece','Greek'] or ret_cc == ['Greek','Greece','Ελληνική'] or ret_cc ==['Greece', 'GREECE'] or ret_cc==['Greece', 'Ελληνική', 'Ελλάδα'] or ret_cc==['ελληνική', 'GREECE'] or ret_cc==['Greek','Ελλάδα','Ελληνική'] or ret_cc==['greek', 'GREECE', 'Greece'] or ret_cc==['greek', 'GREEK'] or ret_cc ==['Greek', 'Greece'] or ret_cc==['Greek', 'Greece'] or ret_cc==['Ελλάδα', 'ΕΛΛΑΔΑ'] or ret_cc==['Ελλάδα', 'Greece'] or ret_cc==['Greek'] or ret_cc==['Ελλάδα', 'Greece'] or ret_cc==['Greek', 'GREECE'] or ret_cc==['Ελλάδα', 'Ελληνική', 'Greece'] or ret_cc==['Greek', 'ΕΛΛΑΔΑ'] or ret_cc==['GREECE', 'Greece'] or ret_cc==['ελληνική', 'Greece'] or ret_cc==['Ελλάδα', 'Ελληνική'] or ret_cc==['Ελλάδα', 'Ελληνική'] or ret_cc==['Greek', 'GREEK', 'Greece'] or ret_cc==['Greece', 'greece'] or ret_cc==['Greek', 'Ελλάδα'] or ret_cc==['Greek', 'GREECE', 'Greece'] or ret_cc==['Greek', 'GREECE', 'Greece'] or ret_cc ==['Greek', 'GREECE', 'Greece'] or ret_cc==['greek','Greece'] or ret_cc==['Ελλάδα','Greece'] or ret_cc==['Greek','GREEK','ελληνική']:\n",
    "        return ret_cc,1\n",
    "    elif ret_cc == []:\n",
    "        return ret_cc,0\n",
    "    else:\n",
    "        return ret_cc,2\n",
    "def check_redirects(url):\n",
    "    import requests\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    r1 = requests.get(r.url)\n",
    "    return r.url,r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_me(url):\n",
    "    url,r1 = check_redirects(url)\n",
    "    print('Emails:')\n",
    "    print(email_crawler(url))\n",
    "    print(' ')\n",
    "    print('Quality certifications:')\n",
    "    print(find_certif(url,r1))\n",
    "    print(' ')\n",
    "    print('Phones:')\n",
    "    print(finder(url,r1))\n",
    "    print(' ')\n",
    "    print('Business name:')\n",
    "    print(business_name(url,r1))\n",
    "    print(' ')\n",
    "    print('Countries and scope of activities:')\n",
    "    print(country_data(url))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emails:\n",
      "['eleni@kouniniotis.gr', 'dmakris@kouniniotis.gr', 'kkavvadias@kouniniotis.gr', 'info@kouniniotis.gr', 'warehouse@kouniniotis.gr', 'webmaster@kouniniotis.gr', 'kmakris@kouniniotis.gr', 'elagel@kouniniotis.gr', 'spinning@kouniniotis.gr', 'lena@kouniniotis.gr', 'sales@kouniniotis.gr', 'thanasis@kouniniotis.gr', 'jmakris@kouniniotis.gr']\n",
      " \n",
      "Quality certifications:\n",
      "['HACCP', 'ISO 22000', 'KIR', 'BRC', 'ISO 22000:2005', 'ISO:22000']\n",
      " \n",
      "Phones:\n",
      "697 667 7598,26910.74473,26910.74484\n",
      " \n",
      "Business name:\n",
      "Couniniotis - family products since 1876\n",
      " \n",
      "Countries and scope of activities:\n",
      "(['Ελλάδα'], 1)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "run_me('http://couniniotis.gr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emails:\n",
      "['info@veler.gr']\n",
      " \n",
      "Quality certifications:\n",
      "['ISO 9001:2008', 'ISO 22000:2005']\n",
      " \n",
      "Phones:\n",
      "210-5787651,210-5744333,2105787651,210-5742054,210-5773182,2105742054,2105773182\n",
      " \n",
      "Business name:\n",
      "VELER ΑΡΑΠΟΣ ΗΡΑΚΛΗΣ Α.Ε\n",
      " \n",
      "Countries and scope of activities:\n",
      "(['Αμερική', 'Ελλάδα', 'Ευρώπη'], 2)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "run_me('http://www.veler.gr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emails:\n",
      "['info@hellasfrost.gr']\n",
      " \n",
      "Quality certifications:\n",
      "['AGRO 2-1', 'AGRO 2-2', 'ISO 22000:2005', 'ISO ', 'EUROCERT']\n",
      " \n",
      "Phones:\n",
      "2553051721,2553051720\n",
      " \n",
      "Business name:\n",
      "Ελληνική Οικοαγροτική Α.Ε\n",
      " \n",
      "Countries and scope of activities:\n",
      "(['Ελλάδα'], 1)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "run_me('http://hellasfrost.gr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emails:\n",
      "['sales@agrimon.gr']\n",
      " \n",
      "Quality certifications:\n",
      "['ISO 22000']\n",
      " \n",
      "Phones:\n",
      "2310 383577,2310 906323\n",
      " \n",
      "Business name:\n",
      "ΚΗΠΟΥΡΟΣ Ι.Κ.Ε\n",
      " \n",
      "Countries and scope of activities:\n",
      "(['Ελλάδα'], 1)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "run_me('http://www.agrimon.gr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emails:\n",
      "['info@kallas-pap.com']\n",
      " \n",
      "Quality certifications:\n",
      "['ISO 2000', 'ISO 9001', 'ISO 9001:2008', 'HACCP', 'ISO 22000', 'ISO 2001', 'ISO 22000:2005']\n",
      " \n",
      "Phones:\n",
      "24210 95338,24210 95314,22620 73086,210 24 01 833,2102401830,26510 57 580,26510 57 567,2710 234 857,210 24 01 830,2710 234 867,22620 73087,2310 723 325,2310 723 324\n",
      " \n",
      "Business name:\n",
      "ΠΑΠΑΔΟΠΟΥΛΟΣ Α.Ε\n",
      " \n",
      "Countries and scope of activities:\n",
      "(['Σκόπια', 'Ρουμανία', 'Βουλγαρία', 'Βαλκάνια', 'Κύπρο', 'Πολωνία', 'Αλβανία', 'Τυνησία', 'Ελλάδα'], 2)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "run_me('http://www.kallas-pap.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emails:\n",
      "['info@viozokat.gr']\n",
      " \n",
      "Quality certifications:\n",
      "['HACCP', 'ISO 22000', 'ISO:', 'ISO 9001']\n",
      " \n",
      "Phones:\n",
      "23510-25228,697 6794183,23510-25222,23210-75488,23210-75802,2310-534309\n",
      " \n",
      "Business name:\n",
      "ΒΙΟΖΩΚΑΤ Α.Ε\n",
      " \n",
      "Countries and scope of activities:\n",
      "(['Ελλάδα'], 1)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "run_me('http://www.viozokat.gr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emails:\n",
      "[]\n",
      " \n",
      "Quality certifications:\n",
      "['ISO ', 'HACCP']\n",
      " \n",
      "Phones:\n",
      "210 9248456\n",
      " \n",
      "Business name:\n",
      "BIOFRESH S.A\n",
      " \n",
      "Countries and scope of activities:\n",
      "(['Ελλάδα', 'Ευρώπη'], 2)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "run_me('http://www.biofresh-sa.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emails:\n",
      "['info@globalclean.gr']\n",
      " \n",
      "Quality certifications:\n",
      "[]\n",
      " \n",
      "Phones:\n",
      "2310-796226\n",
      " \n",
      "Business name:\n",
      "εταιρία  GLOBAL CLEAN\n",
      " \n",
      "Countries and scope of activities:\n",
      "([], 0)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "run_me('http://www.globalclean.gr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emails:\n",
      "['info@pansil.gr']\n",
      " \n",
      "Quality certifications:\n",
      "['ISO 9001:2008']\n",
      " \n",
      "Phones:\n",
      "210 5556300,210 5556555\n",
      " \n",
      "Business name:\n",
      "Pansil ΚΟΡΝΗΛΑΚΗΣ ΑΒΕΕ\n",
      " \n",
      "Countries and scope of activities:\n",
      "(['Ελλάδα'], 1)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "run_me('http://www.pansil.gr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emails:\n",
      "['mail@hfo.gr']\n",
      " \n",
      "Quality certifications:\n",
      "['ISO 22000:2005', 'ΙSO 2200:2005', 'EUROCERT']\n",
      " \n",
      "Phones:\n",
      "210 6384 601,210 6384 600\n",
      " \n",
      "Business name:\n",
      "Ελληνικά Εκλεκτά Έλαια Α.Ε\n",
      " \n",
      "Countries and scope of activities:\n",
      "(['Ελλάδα'], 1)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "run_me('http://www.hfo.gr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emails:\n",
      "['haccp_mk@otenet.gr', 'mak_gi@otenet.gr', 'sales_mk@otenet.gr']\n",
      " \n",
      "Quality certifications:\n",
      "['BRC']\n",
      " \n",
      "Phones:\n",
      "2510 361 484,2510 361 407,2510 361 408\n",
      " \n",
      "Business name:\n",
      "ΑΦΟΙ ΤΣΑΡΟΥΧΑ ΑΕ\n",
      " \n",
      "Countries and scope of activities:\n",
      "(['Ελλάδα', 'Γερμανία'], 2)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "run_me('http://www.tsarouchas.eu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emails:\n",
      "['info@damavand.gr']\n",
      " \n",
      "Quality certifications:\n",
      "['ISO 9001:2008', 'HACCP', 'BRC', 'ISO 22000:2005']\n",
      " \n",
      "Phones:\n",
      "2443 095 000,2443 095 497\n",
      " \n",
      "Business name:\n",
      "Damavand Α.Ε\n",
      " \n",
      "Countries and scope of activities:\n",
      "(['Ελλάδα'], 1)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "run_me('https://www.damavand.gr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emails:\n",
      "['rotosal@otenet.gr', 'athens@rotosal.gr']\n",
      " \n",
      "Quality certifications:\n",
      "['ISO 9001:2008', 'ISO 2015', 'ISO 9001']\n",
      " \n",
      "Phones:\n",
      "210 569 9548,226 102 8208,226 102 3511,210 544 4305\n",
      " \n",
      "Business name:\n",
      "ΛΕΒΑΝΤΗ Α.Β.Ε.Ε\n",
      " \n",
      "Countries and scope of activities:\n",
      "(['Cyprus'], 2)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "run_me('http://rotosal.gr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emails:\n",
      "['cleanway@cleanway.gr']\n",
      " \n",
      "Quality certifications:\n",
      "['ISO 22716', 'BRC', 'ISO 9001']\n",
      " \n",
      "Phones:\n",
      "2102611775,2102617978\n",
      " \n",
      "Business name:\n",
      "CLEANWAY EΠΕ\n",
      " \n",
      "Countries and scope of activities:\n",
      "(['Ελλάδα'], 1)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "run_me('http://cleanway.gr/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
